\documentclass[10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage{color}
\usepackage{caption}
\usepackage{enumerate}
\usepackage{framed}
\usepackage[margin=1in]{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{longtable}
\usepackage{multicol}
\usepackage{natbib}
\usepackage{paralist}
\usepackage{pdfpages}
\usepackage{setspace}
\usepackage{subfigure}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{graphicx} % graphics
\usepackage{epsfig} % eps graphics
\usepackage{hyperref} % urls
\usepackage{booktabs} % table styling
\usepackage{overpic}
\usepackage{fix-cm}
\usepackage{rotating}
\usepackage{transparent}
\usepackage{attrib}
\usepackage{tikz}
\usepackage{multirow}
\usetikzlibrary{arrows,automata,3d}
\usepackage{epstopdf}
\usepackage{epigraph}
\usepackage{sgame}
\usetikzlibrary{calc}

\tikzset{
% Two node styles for game trees: solid and hollow
solid node/.style={circle,draw,inner sep=1.5,fill=black},
hollow node/.style={circle,draw,inner sep=1.5}
}

\newcommand{\tabitem}{~~\llap{\textbullet}~~}

\newcommand{\g}{\ensuremath{G}}
\newcommand{\strat}{\ensuremath{s}}
\newcommand{\strati}[1]{\ensuremath{s_{#1}}}
\newcommand{\stratpro}{\ensuremath{\mathbf{s}}}
\newcommand{\stratproi}[1]{\ensuremath{\mathbf{s}_{#1}}}
\newcommand{\besti}[2]{\ensuremath{B_{#1}\left(#2\right)}}
\newcommand{\EE}[1]{\ensuremath{\operatorname{E}\left[#1\right]}}
\newcommand{\condEE}[2]{\ensuremath{\operatorname{E}\left[#1\Big|#2\right]}}

\newcommand{\solution}[2][show]{                                  % Replace "show" with any other word to hide solutions.
    \ifthenelse{ \equal{#1}{show} }{ \textcolor{blue}{#2}}{}}    % THIS FUNCTION LETS YOU WRITE IN SOLUTIONS BUT HIDE THEM WHEN RENDERING

\title{Problem \# 3}
\author{Ignacio Lara - Game Theory, Spring 2022}
\date{Due: April 19 by 8:30 AM Pacific time}

\begin{document}

\maketitle

%\begin{figure}[h]
%  \centering
%    \includegraphics[width=0.5\textwidth]{../Cartoons/car_traffic_cartoon}
%   \captionsetup{labelformat=empty}
%\end{figure}

\section*{Correlated Equilibria \& Trembling Hand Perfect Equilibria}

As we discussed in the first week, the game of Chicken has two Nash equilibria, neither of which stands out as an ``obvious" choice. If players cannot agree on the same equilibrium, they run the risk of choosing the mutually bad outcome. Therefore, some mechanism is desirable that encourages the players to coordinate on choosing one equilibrium over the other. This problem will explore such a mechanism, as well as two new equilibrium concepts.

\newpage

To explore the first concept, we will work with a model of two drivers approaching an intersection. Each has two options: Stop or Go. If they both Stop, then they are both delayed until they can figure out who should go first. But if they both Go and continue through the intersection, they crash, which is much worse.

\subsection*{Part a}
The game is shown below. We know that (Stop, Go) and and (Go, Stop) are both pure strategy Nash equilibria. What is the mixed strategy Nash equilibrium? Show your work for full credit.
\begin{center}
\begin{game}{2}{2}[Driver 1][Driver 2]
 & Stop & Go\\
Stop & -2,-2 & -1,1\\
Go & 1,-1 & -10,-10
\end{game}
\end{center}

The mixed strategy Nash equilibrium occurs when each driver randomizes their choice of Stop and Go such that the other is indifferent between their two choices. Let $p$ represent the probability Driver 1 chooses Stop, and $q$ represent the probability that Driver 2 chooses Stop:
\begin{center}
	\begin{game}{2}{2}[Driver 1][Driver 2]
		& Stop ($q$) & Go ($1-q$)\\
		Stop ($p$) & -2,-2 & -1,1\\
		Go ($1-p$)& 1,-1 & -10,-10
	\end{game}
\end{center}

So Driver 1 would choose $p$ such that Driver 2's expected payoff is the same, whether Driver 2 chooses Stop or Go. Driver 2 will receive the top row payoff with probability $p$, and the bottom row payoff with probability $1-p$. Each side of the equation will represent one of Driver 2's choices, i.e. the left side of the equation represents Driver 2's expected payoff from Stop, and the right side represents Driver 2's expected payoff from Go:
\[
\begin{aligned}
p(-2) + (1-p)(-1) &= p(1) + (1-p)(-10) \\
-2p -1 + p &= p - 10 + 10p \\
-p - 1 &= 11p - 10 \\
9 &= 12p \\
p^* &= \frac{9}{12} = \frac{3}{4}
\end{aligned}
\]

Similarly, Driver 2 would choose $q$ such that Driver 1's expected payoff is the same, whether Driver 1 chooses Stop or Go. Driver 1 will receive the left payoff with probability $q$, and the right payoff with probability $1-q$. In the equation, the left hand side represents Driver 1's expected payoff from choosing Stop, and the right hand side represents Driver 1's expected payoff from choosing Go:
\[
	q(-2) + (1-q)(-1) = q(1) + (1-q)(-10)
\]

Given the symmetry of the payoff matrix (i.e., substituting $p$ for $q$ gives us the exact same equation we had above), we can take a shortcut and arrive at $q^* = \frac{3}{4}$.

So, the mixed  strategy Nash equilibrium is: \textbf{both drivers choose Stop with probability 0.75, and Go with probability 0.25}. In ``math" notation, we can represent the equilibrium as: 
\[
(0.75[\text{Stop}] + 0.25[\text{Go}], \: 0.75[\text{Stop}] + 0.25[\text{Go}])
\]
\newpage

\subsection*{Part b}
What is the equilibrium probability of crashing (i.e. both playing ``Go"), and what is the overall equilibrium expected payoff of each player?
\\ \\
We're assuming a simultaneous game, and no communication or prior beliefs about the other drivers beyond a belief in their rationality and ability to arrive at the Nash equilibrium. Then the probability that one Driver chooses Go is independent of the other driver's choice, so the probability of (Go, Go) is simply the product of each Driver's probability of choosing Go:
\[
\Pr{(\text{Go, Go})} = \frac{1}{4} \times \frac{1}{4} = \frac{1}{16}
\]

The probabilities of the other outcomes can be calculated similarly:
\renewcommand{\gamestretch}{1.5}
\begin{center}
	\begin{game}{2}{2}[Driver 1][Driver 2]
		& Stop ($q=0.75$) & Go ($1-q=0.25$)\\
		Stop ($p=0.75$) & $\frac{3}{4} \times \frac{3}{4} = \frac{9}{16} \: (-2,-2)$ & $\frac{3}{4} \times \frac{1}{4} = \frac{3}{16} \: (-1,1)$\\
		Go ($1-p=0.25$)& $\frac{1}{4} \times \frac{3}{4} = \frac{3}{16} \: (1,-1)$ & $\frac{1}{4} \times \frac{1}{4} = \frac{1}{16} \: (-10,-10)$
	\end{game}
\end{center}

Each player's equilibrium expected payoff is simply their payoff for each outcome, weighted by the probability of arriving at that outcome. For Driver 1:
\[
\begin{aligned}
\mathbb{E}(V) &= \frac{9}{16}(-2) + \frac{3}{16}(-1) + \frac{3}{16}(1) + \frac{1}{16}(-10) \\ \\
              &= \frac{-18}{16} + \frac{-3}{16} + \frac{3}{16} + \frac{-10}{16} \\ \\
              &= \frac{-28}{16} = \frac{-7}{4} = -1.75
\end{aligned}
\]
Again, we can rely on symmetry to safely say that -1.75 is also Driver 2's expected equilibrium payoff.
\newpage

\subsection*{Part c}
Now we introduce the stoplight. The stoplight serves as a \emph{public signal}; in other words, it is visible to everyone and allows drivers a chance to coordinate their responses. There are two possible signals, which we describe as a pair of colors. The first color is shown to Driver 1, and the second color to Driver 2. The signals are $\gamma_1=(Red,Green)$ and $\gamma_2=(Green,Red)$. Each signal is shown with probability $\frac{1}{2}$.

In a correlated equilibrium, each player chooses a strategy (possibly a mixed strategy) to use for \emph{each} signal. If the strategies are mutual best responses, then the equilibrium holds. In this case, find a pair of mutual best responses for each signal. Explain your logic briefly to defend your answer.
\\ \\
\begin{center}
	\begin{game}{2}{2}[Driver 1][Driver 2]
		& Stop & Go\\
		Stop & -2,-2 & -1,1\\
		Go & 1,-1 & -10,-10
	\end{game}
\end{center}
Because there are only two signals, and two options per signal, there is no difference here in observing only your own signal, or observing both your and the other driver's signals (because observing your own can tell you exactly what the other driver's is). So, if Driver 1 sees Red ($\gamma_1$), they know that Driver 2 sees Green, and vice versa for $\gamma_2$. The question becomes whether either Driver has an incentive to deviate from their ``assigned" strategy (operating under the assumption that both drivers understand Red to mean stop, and Green to mean go). 

If Driver 1 sees Red, is there an incentive to ``defy" the signal, and Go anyway? If Driver 1 believes that Driver 2 will comply with their signal and Go, then Driver 1 receives a payoff of -1 by ``complying" and choosing Stop, versus a payoff of -10 by ``defying" and choosing Go. There is no incentive for Driver 1 to deviate from the signal's suggestion. Driver 2, if believing that Driver 1 would comply and Stop, receives a payoff of 1 by complying and choosing Go, versus a payoff of -2 by defying and choosing Stop. So Driver 2 does not have an incentive to deviate from the signal. This is then a valid, correlated equilibrium.

Again, by relying on symmetry, we can conclude that the correlated equilibrium exists whether signal $\gamma_1$ or $\gamma_2$ is shown.
  

\newpage

\subsection*{Part d} In the correlated equilibrium, what is the probability that the drivers crash, and what is the expected payoff of each driver prior to approaching the stoplight?
\\ \\
Since both drivers strictly prefer complying to defying their signal, the probability that the drivers crash by ending up in (Go, Go) is zero. Regardless of whether $\gamma_1$ or $\gamma_2$ is shown, one driver will Stop and the other will Go. 

Before approaching the stoplight, the probability of observing either signal is one half, i.e. $\Pr{(\gamma_1)} = \Pr{(\gamma_2)} = 0.5$. So the drivers' expected payoffs are the average of their payoffs under $\gamma_1$ and $\gamma_2$. From the above, Driver 1's expected payoff under $\gamma_1$ is -1; under $\gamma_2$ it is 1, for an expected payoff of 0. Driver 2's payoffs are reversed, but still average to 0.

\newpage

\subsection*{Part e} Now consider another game with two equilibria: Stag Hunt. Another theory of how people choose an equilibrium is that it should be stable to perturbations--in other words, if an opponent makes a mistake, or has a very small probability of playing a different action, a player should still want to stick with their equilibrium strategy. Consider the variation on the Stag Hunt game below:
\begin{center}
\begin{game}{2}{2}[Player 1][Player 2]
 & Stag & Hare\\
Stag & 3,3 & 0,3\\
Hare & 3,0 & 1,1
\end{game}
\end{center}
You can verify that both (Stag,Stag) and (Hare,Hare) are Nash equilibria. Suppose that one player plays Stag but has a small probability $\epsilon$ of ``accidentally" playing Hare, so their strategy is $(1-\epsilon)[Stag]+\epsilon[Hare]$. What is the other player's best response? (Note: By ``small" we mean that you can assume $\epsilon$ is much smaller than 1.)
\\ \\
Without loss of generality, assume Player 2 is the one prone to blunder, such that the game becomes:
\begin{center}
	\begin{game}{2}{2}[Player 1][Player 2]
		& Stag ($1-\epsilon$) & Hare ($\epsilon$)\\
		Stag & 3,3 & 0,3\\
		Hare & 3,0 & 1,1
	\end{game}
\end{center}

How big would $\epsilon$ need to be to induce Player 1 to mix? Let's calculate Player 1's expected payoffs. (LHS represents payoffs from choosing Stag, RHS represents payoffs from choosing Hare).
\[
\begin{aligned}
	(1-\epsilon)(3) + \epsilon(0) &\overset{?}{=} (1-\epsilon)(3) + \epsilon(1) \\
	3 - 3\epsilon &\overset{?}{=} 3 - 3\epsilon + \epsilon \\
	3 - 3\epsilon &\overset{?}{=} 3 - 2\epsilon
\end{aligned}
\]
Uh oh. For any $\epsilon > 0$, Player 1 strictly prefers Hare to Stag. So technically, Player 1's best response to an imperfect Player 2 is to play Hare. But Player 2's best response if Player 1 plays Hare is to also play Hare, meaning their original strategy no longer holds, and suggesting that the players will end up at (Hare, Hare) (because Player 1's best response if Player 2 plays Hare is to play Hare, so the ``cycle" is closed). Even if $\epsilon << 1 \Longrightarrow 2\epsilon, \: 3\epsilon << 1$, Hare's weak domination of Stag means that Hare is preferred when Player 2's probability of Stag is anything less than certain.

If, however, $\epsilon$ is so small that Player 1 really doesn't perceive it, then maybe the Stag Hunt can survive at (Stag, Stag) despite Player 2's imperfections, since the difference in Player 1's expected payoffs is only one $\epsilon$.

\newpage

\subsection*{Part f} Suppose instead one player plays $\epsilon[Stag]+(1-\epsilon)[Hare]$. What is the other player's best response?
\\ \\
For the sake of consistency, and because we generally dislike Player 2, let's continue with their imperfection:
\begin{center}
	\begin{game}{2}{2}[Player 1][Player 2]
		& Stag ($\epsilon$) & Hare ($1-\epsilon$)\\
		Stag & 3,3 & 0,3\\
		Hare & 3,0 & 1,1
	\end{game}
\end{center}

Like before, we can look at Player 1's expected payoffs (LHS: Stag, RHS: Hare):
\[
\begin{aligned}
	\epsilon(3) + (1-\epsilon)(0) &\overset{?}{=} \epsilon(3) + (1-\epsilon)(1) \\
	3\epsilon &\overset{?}{=} 3\epsilon + 1 - \epsilon \\
	0 &\overset{?}{=} 1 - \epsilon
\end{aligned}
\]

If $\epsilon << 1 \Longrightarrow 1 - \epsilon > 0$, so Player 1 strictly prefers Hare to Stag. If Player 1 plays Hare, Player 2's best response is to play Hare, so this scenario ``survives." (Unlike the hare.)
\newpage

\subsection*{Part g} A trembling-hand perfect equilibrium is a pure strategy Nash equilibrium in which each player's strategy is still a best response if their opponent instead uses a mixed strategy in which there is a very small chance of deviating from the equilibrium action. Which of the two pure strategy Nash equilibria in this game are trembling-hand perfect? Justify your answer briefly.
\\ \\ 
(Hare, Hare) is trembling-hand perfect, because any deviation from pure Stag forces the ``perfect" player to Hare, at which point Hare becomes the best response for the trembling-hand player. See part (f).

\newpage

\subsection*{Part h (OPTIONAL, not graded, just for practice)} In the stoplight setting from part (c), suppose instead there are 3 signals: (Red, Green), (Green, Red), and (Red,Red). This means that when a player sees a red light, they are unsure if the other driver also sees red, or if they see green. Suppose the probabilities are as follows: (Red, Green) and (Green, Red) each have probability 0.4, and (Red, Red) has probability 0.2.

Find strategies that constitute a correlated equilibrium. What are the expected payoffs in this case? (Hint: You will have to use some additional math to show that these are indeed best responses, and you may need Bayes' rule to find conditional probabilities. We will discuss Bayes' rule in Chapter 8.)
\\ \\
Let $\gamma_1 = \text{(Red, Green)}$, $\gamma_2 = \text{(Green, Red)}$, $\gamma_3 = \text{(Red, Red)}$. If Driver 1 sees Red, then the signal is either $\gamma_1$ or $\gamma_3$. \\
\[
\Pr(\gamma_1 \: | \: \text{Driver 1 Red}) = \frac{\Pr(\text{Driver 1 Red} \: | \: \gamma_1) \cdot \Pr(\gamma_1)}{\Pr(\text{Driver 1 Red)}}
\]

If $\gamma_1$ is shown, we know Driver 1 sees Red, so $\Pr(\text{Driver 1 Red} \: | \: \gamma_1) = 1$. We are given $\Pr(\gamma_1) = 0.4$. Finally, Driver 1 sees Red in either $\gamma_1$ or $\gamma_3$, so $\Pr(\text{Driver 1 Red)} = \Pr(\gamma_1) + \Pr(\gamma_3) = 0.6$. Thus:
\\
\[
\Pr(\gamma_1 \: | \: \text{Driver 1 Red}) = \frac{1 \cdot 0.4}{0.6} = \frac{2}{3}
\]

Note this also means $\Pr(\gamma_3 \: | \: \text{Driver 1 Red}) = 1 - \Pr(\gamma_1 \: | \: \text{Driver 1 Red}) = 1/3$, because $\gamma_2$ has zero probability if we condition on Driver 1 seeing Red. If we again assume that Driver 2 will comply with their signal, is there any incentive for Driver 1 to deviate?
\begin{center}
	\begin{game}{2}{2}[Driver 1][Driver 2]
		& Stop & Go\\
		Stop & -2,-2 & -1,1\\
		Go & 1,-1 & -10,-10
	\end{game}
\end{center}

So if Driver 1 complies by choosing Stop, there is a $2/3$ chance that Driver 2 is going, and a $1/3$ chance that Driver 2 is stopping. Driver 1's expected payoffs from Stop are thus $2/3(-1) + 1/3(-2) = -1$, and from Go: $2/3(-10) + 1/3(1) = -19/3$; Driver 1 should comply. Is Driver 2 complying a Best Response to this? If Driver 2 sees Green, then only $\gamma_1$ is possible, and Driver 2 would Go because he knows Driver 1 would stop. So this would be a correlated equilibrium. If Driver 2 sees Red, then we are in the same situation as before, and Driver 2 would choose to comply and Stop. At which point Driver 1's best response is to Go.

That's as far as my train of thought could take me... 
\end{document}
